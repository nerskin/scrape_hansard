{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to ingest the Hansard XML dumps, extract the information I care about, and write it to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import multiprocessing\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir('./data/')\n",
    "data_files = [f for f in data_files if re.match('.*xml',f)]\n",
    "data_files = ['./data/'+data_file for data_file in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speech:\n",
    "    \"\"\"Class to represent a speech in parliament\"\"\"\n",
    "    \n",
    "    def __init__(self,speech):\n",
    "        \"\"\"Should only be called from the constructor for Debate\"\"\"\n",
    "        self.name = speech.find('name').get_text()\n",
    "        self.text = speech.find('talk.text').get_text()\n",
    "        self.party = speech.find('party').get_text()\n",
    "\n",
    "class Division:\n",
    "    \n",
    "    def __init__(self,division,i):\n",
    "        self.id = i\n",
    "        self.result = division.find('division.result').get_text().strip()\n",
    "        self.ayes = [name_tag.get_text() for name_tag in division.find('ayes').find_all('name')]\n",
    "        try:\n",
    "            self.noes = [name_tag.get_text() for name_tag in division.find('noes').find_all('name')]\n",
    "        except:\n",
    "            self.noes = []\n",
    "        parent = division.parent\n",
    "        grandparent = parent.parent\n",
    "        self.parent_title = parent.title.get_text()\n",
    "        self.grandparent_title = grandparent.title.get_text()\n",
    "        \n",
    "class Subdebate:\n",
    "    \n",
    "    def __init__(self,subdebate,i):\n",
    "        self.id = i\n",
    "        self.title = subdebate.find('title')\n",
    "        self.speeches = [Speech(speech) for speech in subdebate.find_all('speech')]\n",
    "        self.divisions = [Division(division,i) for i,division in enumerate(subdebate.find_all('division'))]\n",
    "\n",
    "class Debate:\n",
    "    \"\"\"Class to represent a debate in parliament\"\"\"\n",
    "    \n",
    "    def __init__(self,debate,i):\n",
    "        \"\"\"Should only be called from the constructor for SittingDay\"\"\"\n",
    "        self.id = i\n",
    "        self.title = debate.find('title')\n",
    "        self.subdebates = list()\n",
    "        self.type = debate.type.get_text()\n",
    "        subdebate = True\n",
    "        i = 1\n",
    "        while subdebate:\n",
    "            subdebate=debate.find('subdebate.'+str(i))\n",
    "            i+=1\n",
    "            if subdebate:\n",
    "                self.subdebates.append(Subdebate(subdebate,i-1))\n",
    "        \n",
    "        \n",
    "        \n",
    "class SittingDay:\n",
    "    \"\"\"Class to represent a whole parliamentary sitting day\"\"\"\n",
    "    \n",
    "    def __init__(self,day):\n",
    "        \"\"\"takes a beautifulsoup object\"\"\"\n",
    "        self.date = day.find('date').get_text()\n",
    "        debates = day.find_all('debate')\n",
    "        self.debates = [Debate(debate,i) for i,debate in enumerate(debates)]\n",
    "        self.chamber = day.find('chamber').get_text()\n",
    "        if self.chamber == 'House of Reps':\n",
    "            self.chamber = 'HoR'\n",
    "        \n",
    "    def write_divisions(self,path = '.'):\n",
    "        name = list()\n",
    "        vote = list()\n",
    "        date = list()\n",
    "        parent_title = list()\n",
    "        grandparent_title = list()\n",
    "        debate_type = list()\n",
    "        debate_id = list()\n",
    "        subdebate_id = list()\n",
    "        chamber = list()\n",
    "        division_id = list()\n",
    "        for debate in self.debates:\n",
    "            for subdebate in debate.subdebates:\n",
    "                for division in subdebate.divisions:\n",
    "                    all_names = division.ayes + division.noes\n",
    "                    for member in all_names:\n",
    "                        name.append(member)\n",
    "                        if member in division.ayes:\n",
    "                            vote.append('aye')\n",
    "                        if member in division.noes:\n",
    "                            vote.append('no')\n",
    "                        date.append(self.date)\n",
    "                        chamber.append(self.chamber)\n",
    "                        parent_title.append(division.parent_title)\n",
    "                        grandparent_title.append(division.grandparent_title)\n",
    "                        debate_type.append(debate.type)\n",
    "                        debate_id.append(debate.id)\n",
    "                        subdebate_id.append(subdebate.id)\n",
    "                        division_id.append(division.id)\n",
    "                            \n",
    "        data_frame = pd.DataFrame({'name':name,'vote':vote,'parent_title':parent_title,'grandparent_title':grandparent_title,\n",
    "                                   'date':date,'chamber':chamber,'debate_type':debate_type,'debate_id':debate_id,'subdebate_id':subdebate_id,'division_id':division_id})\n",
    "        data_frame.to_csv(path+'/'+self.date + '-' + self.chamber + '-' + 'divisions.csv',encoding = 'utf-8',index = False)\n",
    "        \n",
    "    def write_speeches(self,path='.'):\n",
    "        \"\"\"Write all the debates to a csv file (one file per day)\"\"\"\n",
    "        #ToDo: extend to also include votes\n",
    "        text = list()\n",
    "        name = list()\n",
    "        party = list()\n",
    "        date = list()\n",
    "        debate_title = list()\n",
    "        subdebate_title = list()\n",
    "        debate_type = list()\n",
    "        chamber=list()\n",
    "        debate_id = list()\n",
    "        for debate in self.debates:\n",
    "            for subdebate in debate.subdebates:\n",
    "                for speech in subdebate.speeches:\n",
    "                    text.append(speech.text)\n",
    "                    name.append(speech.name)\n",
    "                    party.append(speech.party)\n",
    "                    date.append(self.date)\n",
    "                    debate_title.append(debate.title)\n",
    "                    subdebate_title.append(subdebate.title)\n",
    "                    debate_type.append(debate.type)\n",
    "                    chamber.append(self.chamber)\n",
    "                    debate_id.append(debate.id)\n",
    "        data_frame = pd.DataFrame({'name':name,'party':party,'date':date,'text':text,'chamber':chamber,'debate_title':debate_title,'subdebate_title':subdebate_title,'debate_type':debate_type,'debate_id':debate_id})\n",
    "        data_frame.to_csv(path + '/' + self.date+ '-' + self.chamber +'-speeches.csv',encoding='utf-8',index=False)\n",
    "        \n",
    "    def write_proceedings(self,speeches_path='.',divisions_path='.'):\n",
    "        self.write_speeches(speeches_path)\n",
    "        self.write_divisions(divisions_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FixMe:\n",
    "* ~~Split up debates into subdebates~~\n",
    "* ~~Add divisions~~\n",
    "* Add dictionary to associate MPs' names as listed in divisions with their names as listed elsewhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since building the BeautifulSoup representation of each XML file is somewhat slow, it's worth parallelising the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(x):\n",
    "    data_file = x[0]\n",
    "    speeches_path = x[1]\n",
    "    divisions_path = x[2]\n",
    "    with open(data_file,'r') as f:\n",
    "        SittingDay(BeautifulSoup(f.read(),'lxml')).write_proceedings(speeches_path,divisions_path)\n",
    "    return 'done'\n",
    "\n",
    "(speeches_path,divisions_path) = ('../tidied_parliamentary_data/speeches','../tidied_parliamentary_data/divisions')\n",
    "\n",
    "try:\n",
    "    os.makedirs(speeches_path)\n",
    "except OSError:\n",
    "    pass #nothing to do if the directories already exist\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(divisions_path)\n",
    "except OSError:\n",
    "    pass #nothing to do if the directories already exist\n",
    "\n",
    "input = [(data_file,speeches_path,divisions_path) for data_file in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 70.4 ms, total: 229 ms\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "pool.map(xml_to_csv,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bandt, AP',\n",
       "  'Bird, SL',\n",
       "  'Bowen, CE',\n",
       "  'Burke, AS',\n",
       "  'Butler, MC',\n",
       "  'Butler, TM',\n",
       "  'Byrne, AM',\n",
       "  'Chalmers, JE',\n",
       "  'Champion, ND',\n",
       "  'Chesters, LM',\n",
       "  'Clare, JD',\n",
       "  'Claydon, SC',\n",
       "  'Collins, JM',\n",
       "  'Conroy, PM',\n",
       "  'Dreyfus, MA',\n",
       "  'Elliot, MJ',\n",
       "  'Ellis, KM',\n",
       "  'Ferguson, LDT',\n",
       "  'Fitzgibbon, JA',\n",
       "  'Giles, AJ',\n",
       "  'Gray, G',\n",
       "  'Hall, JG (teller)',\n",
       "  'Hayes, CP',\n",
       "  'Husic, EN',\n",
       "  'Jones, SP',\n",
       "  'King, CF',\n",
       "  'Leigh, AK',\n",
       "  'Macklin, JL',\n",
       "  'MacTiernan, AJGC',\n",
       "  'Marles, RD',\n",
       "  'McGowan, C',\n",
       "  'Mitchell, RG',\n",
       "  'Neumann, SK',\n",
       "  \"O'Connor, BPJ\",\n",
       "  \"O'Neil, CE\",\n",
       "  'Owens, J',\n",
       "  'Parke, M',\n",
       "  'Plibersek, TJ',\n",
       "  'Ripoll, BF',\n",
       "  'Rishworth, AL',\n",
       "  'Rowland, MA',\n",
       "  'Ryan, JC (teller)',\n",
       "  'Snowdon, WE',\n",
       "  'Swan, WM',\n",
       "  'Thistlethwaite, MJ',\n",
       "  'Thomson, KJ',\n",
       "  'Vamvakinou, M',\n",
       "  'Watts, TG',\n",
       "  'Wilkie, AD',\n",
       "  'Zappia, A'],\n",
       " ['Bandt, AP',\n",
       "  'Bird, SL',\n",
       "  'Bowen, CE',\n",
       "  'Burke, AS',\n",
       "  'Butler, MC',\n",
       "  'Butler, TM',\n",
       "  'Byrne, AM',\n",
       "  'Chalmers, JE',\n",
       "  'Champion, ND',\n",
       "  'Chesters, LM',\n",
       "  'Clare, JD',\n",
       "  'Claydon, SC',\n",
       "  'Collins, JM',\n",
       "  'Conroy, PM',\n",
       "  'Dreyfus, MA',\n",
       "  'Elliot, MJ',\n",
       "  'Ellis, KM',\n",
       "  'Ferguson, LDT',\n",
       "  'Fitzgibbon, JA',\n",
       "  'Giles, AJ',\n",
       "  'Gray, G',\n",
       "  'Hall, JG (teller)',\n",
       "  'Hayes, CP',\n",
       "  'Husic, EN',\n",
       "  'Jones, SP',\n",
       "  'King, CF',\n",
       "  'Leigh, AK',\n",
       "  'Macklin, JL',\n",
       "  'MacTiernan, AJGC',\n",
       "  'Marles, RD',\n",
       "  'McGowan, C',\n",
       "  'Mitchell, RG',\n",
       "  'Neumann, SK',\n",
       "  \"O'Connor, BPJ\",\n",
       "  \"O'Neil, CE\",\n",
       "  'Owens, J',\n",
       "  'Parke, M',\n",
       "  'Plibersek, TJ',\n",
       "  'Ripoll, BF',\n",
       "  'Rishworth, AL',\n",
       "  'Rowland, MA',\n",
       "  'Ryan, JC (teller)',\n",
       "  'Snowdon, WE',\n",
       "  'Swan, WM',\n",
       "  'Thistlethwaite, MJ',\n",
       "  'Thomson, KJ',\n",
       "  'Vamvakinou, M',\n",
       "  'Watts, TG',\n",
       "  'Wilkie, AD',\n",
       "  'Zappia, A'],\n",
       " ['Bandt, AP',\n",
       "  'Bird, SL',\n",
       "  'Bowen, CE',\n",
       "  'Burke, AS',\n",
       "  'Butler, MC',\n",
       "  'Butler, TM',\n",
       "  'Byrne, AM',\n",
       "  'Chalmers, JE',\n",
       "  'Champion, ND',\n",
       "  'Chesters, LM',\n",
       "  'Clare, JD',\n",
       "  'Claydon, SC',\n",
       "  'Collins, JM',\n",
       "  'Conroy, PM',\n",
       "  'Dreyfus, MA',\n",
       "  'Elliot, MJ',\n",
       "  'Ellis, KM',\n",
       "  'Ferguson, LDT',\n",
       "  'Fitzgibbon, JA',\n",
       "  'Giles, AJ',\n",
       "  'Gray, G',\n",
       "  'Hall, JG (teller)',\n",
       "  'Hayes, CP',\n",
       "  'Husic, EN',\n",
       "  'Jones, SP',\n",
       "  'King, CF',\n",
       "  'Leigh, AK',\n",
       "  'Macklin, JL',\n",
       "  'MacTiernan, AJGC',\n",
       "  'Marles, RD',\n",
       "  'Mitchell, RG',\n",
       "  'Neumann, SK',\n",
       "  \"O'Connor, BPJ\",\n",
       "  \"O'Neil, CE\",\n",
       "  'Owens, J',\n",
       "  'Parke, M',\n",
       "  'Plibersek, TJ',\n",
       "  'Ripoll, BF',\n",
       "  'Rishworth, AL',\n",
       "  'Rowland, MA',\n",
       "  'Ryan, JC (teller)',\n",
       "  'Snowdon, WE',\n",
       "  'Swan, WM',\n",
       "  'Thistlethwaite, MJ',\n",
       "  'Thomson, KJ',\n",
       "  'Vamvakinou, M',\n",
       "  'Watts, TG',\n",
       "  'Wilkie, AD',\n",
       "  'Zappia, A'],\n",
       " ['Alexander, JG',\n",
       "  'Andrews, KJ',\n",
       "  'Baldwin, RC',\n",
       "  'Billson, BF',\n",
       "  'Bishop, BK',\n",
       "  'Bishop, JI',\n",
       "  'Broad, AJ',\n",
       "  'Broadbent, RE',\n",
       "  'Brough, MT',\n",
       "  'Buchholz, S',\n",
       "  'Christensen, GR',\n",
       "  'Cobb, JK',\n",
       "  'Coleman, DB',\n",
       "  'Coulton, M (teller)',\n",
       "  'Entsch, WG',\n",
       "  'Fletcher, PW',\n",
       "  'Frydenberg, JA',\n",
       "  'Gambaro, T',\n",
       "  'Gillespie, DA',\n",
       "  'Goodenough, IR',\n",
       "  'Griggs, NL',\n",
       "  'Hartsuyker, L',\n",
       "  'Hawke, AG',\n",
       "  'Henderson, SM',\n",
       "  'Hendy, PW',\n",
       "  'Hockey, JB',\n",
       "  'Hogan, KJ',\n",
       "  'Howarth, LR',\n",
       "  'Hunt, GA',\n",
       "  'Hutchinson, ER',\n",
       "  'Irons, SJ',\n",
       "  'Jensen, DG',\n",
       "  'Jones, ET',\n",
       "  'Joyce, BT',\n",
       "  'Keenan, M',\n",
       "  'Kelly, C',\n",
       "  'Laming, A',\n",
       "  'Landry, ML',\n",
       "  'Laundy, C',\n",
       "  'Ley, SP',\n",
       "  'Macfarlane, IE',\n",
       "  'Marino, NB',\n",
       "  'Markus, LE',\n",
       "  'Matheson, RG',\n",
       "  'McCormack, MF',\n",
       "  'McNamara, KJ',\n",
       "  'Morrison, SJ',\n",
       "  'Nikolic, AA (teller)',\n",
       "  \"O'Dowd, KD\",\n",
       "  \"O'Dwyer, KM\",\n",
       "  'Pasin, A',\n",
       "  'Pitt, KJ',\n",
       "  'Porter, CC',\n",
       "  'Prentice, J',\n",
       "  'Price, ML',\n",
       "  'Pyne, CM',\n",
       "  'Ramsey, RE',\n",
       "  'Robert, SR',\n",
       "  'Roy, WB',\n",
       "  'Ruddock, PM',\n",
       "  'Scott, BC',\n",
       "  'Scott, FM',\n",
       "  'Simpkins, LXL',\n",
       "  'Southcott, AJ',\n",
       "  'Stone, SN',\n",
       "  'Sudmalis, AE',\n",
       "  'Sukkar, MS',\n",
       "  'Taylor, AJ',\n",
       "  'Tehan, DT',\n",
       "  'Truss, WE',\n",
       "  'Tudge, AE',\n",
       "  'Van Manen, AJ',\n",
       "  'Vasta, RX',\n",
       "  'Whiteley, BD',\n",
       "  'Wicks, LE',\n",
       "  'Williams, MP',\n",
       "  'Wilson, RJ',\n",
       "  'Wood, JP',\n",
       "  'Wyatt, KG']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_files[110],'r') as f:\n",
    "    x = f.read()\n",
    "divs = list()\n",
    "for debate in SittingDay(BeautifulSoup(x)).debates:\n",
    "    for subdebate in debate.subdebates:\n",
    "        divs += subdebate.divisions\n",
    "        \n",
    "[div.noes for div in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(x)\n",
    "soup.find_all('division')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
